{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69974bc7",
   "metadata": {},
   "source": [
    "<h1> Energy Efficiency of Buildings </h1>\n",
    "<br>\n",
    "    <q>This notebook has been made for the project at<a href=\"https://app.patika.dev/moduller/dspg-projeleri/binalar%C4%B1n_enerji_verimliligi\"> patika.dev </a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0e187",
   "metadata": {},
   "source": [
    "<h3> Dataset </h3>\n",
    "<br>\n",
    "The data used in the project was obtained from the <a href=\"https://www.kaggle.com/elikplim/eergy-efficiency-dataset\"> Energy Efficiency Dataset</a>.\n",
    "<br><br>\n",
    "The dataset contains eight attributes (or features, denoted by X1…X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7e7cb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cc83f",
   "metadata": {},
   "source": [
    "<h2> Download and Read Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83dc3d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>17.88</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.44</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.48</td>\n",
       "      <td>16.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.62</td>\n",
       "      <td>808.5</td>\n",
       "      <td>367.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>16.64</td>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
       "0    0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
       "1    0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
       "2    0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
       "3    0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
       "4    0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28\n",
       "..    ...    ...    ...     ...  ...  ..  ...  ..    ...    ...\n",
       "763  0.64  784.0  343.0  220.50  3.5   5  0.4   5  17.88  21.40\n",
       "764  0.62  808.5  367.5  220.50  3.5   2  0.4   5  16.54  16.88\n",
       "765  0.62  808.5  367.5  220.50  3.5   3  0.4   5  16.44  17.11\n",
       "766  0.62  808.5  367.5  220.50  3.5   4  0.4   5  16.48  16.61\n",
       "767  0.62  808.5  367.5  220.50  3.5   5  0.4   5  16.64  16.03\n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading data\n",
    "df = pd.read_csv('ENB2012_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee85a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    0\n",
      "X2    0\n",
      "X3    0\n",
      "X4    0\n",
      "X5    0\n",
      "X6    0\n",
      "X7    0\n",
      "X8    0\n",
      "Y1    0\n",
      "Y2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#detecting missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c4475",
   "metadata": {},
   "source": [
    "We don't have any missing values.\n",
    "<br>\n",
    "<br>\n",
    "We don't have any categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d534bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#checking for outliers\n",
    "\n",
    "#z-score\n",
    "from scipy import stats as st\n",
    "z = np.abs(st.zscore(df))\n",
    "print(np.where(z > 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8a8f1",
   "metadata": {},
   "source": [
    "We don't have any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b148d1",
   "metadata": {},
   "source": [
    "<h2> Split Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afee4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train         X1     X2     X3      X4   X5  X6    X7  X8     Y1     Y2\n",
      "668  0.62  808.5  367.5  220.50  3.5   2  0.40   3  16.47  16.90\n",
      "324  0.66  759.5  318.5  220.50  3.5   2  0.25   1  13.17  16.39\n",
      "624  0.98  514.5  294.0  110.25  7.0   2  0.40   3  32.82  32.78\n",
      "690  0.79  637.0  343.0  147.00  7.0   4  0.40   4  41.32  46.23\n",
      "473  0.64  784.0  343.0  220.50  3.5   3  0.25   4  16.69  19.76\n",
      "..    ...    ...    ...     ...  ...  ..   ...  ..    ...    ...\n",
      "190  0.62  808.5  367.5  220.50  3.5   4  0.10   3  12.71  14.14\n",
      "115  0.79  637.0  343.0  147.00  7.0   5  0.10   2  36.03  42.86\n",
      "732  0.82  612.5  318.5  147.00  7.0   2  0.40   5  30.00  29.93\n",
      "467  0.69  735.0  294.0  220.50  3.5   5  0.25   4  12.86  16.13\n",
      "94   0.62  808.5  367.5  220.50  3.5   4  0.10   1  12.93  14.33\n",
      "\n",
      "[460 rows x 10 columns]\n",
      "validate         X1     X2     X3      X4   X5  X6    X7  X8     Y1     Y2\n",
      "180  0.66  759.5  318.5  220.50  3.5   2  0.10   3  11.59  13.46\n",
      "301  0.82  612.5  318.5  147.00  7.0   3  0.25   1  27.27  27.84\n",
      "736  0.79  637.0  343.0  147.00  7.0   2  0.40   5  42.11  38.56\n",
      "569  0.64  784.0  343.0  220.50  3.5   3  0.40   1  19.36  22.73\n",
      "628  0.90  563.5  318.5  122.50  7.0   2  0.40   3  34.24  37.26\n",
      "..    ...    ...    ...     ...  ...  ..   ...  ..    ...    ...\n",
      "384  0.98  514.5  294.0  110.25  7.0   2  0.25   3  28.67  29.43\n",
      "224  0.69  735.0  294.0  220.50  3.5   2  0.10   4  11.18  14.29\n",
      "729  0.86  588.0  294.0  147.00  7.0   3  0.40   5  31.81  31.20\n",
      "630  0.90  563.5  318.5  122.50  7.0   4  0.40   3  35.05  33.82\n",
      "472  0.64  784.0  343.0  220.50  3.5   2  0.25   4  16.99  19.65\n",
      "\n",
      "[154 rows x 10 columns]\n",
      "test         X1     X2     X3      X4   X5  X6    X7  X8     Y1     Y2\n",
      "347  0.86  588.0  294.0  147.00  7.0   5  0.25   2  28.40  34.52\n",
      "505  0.74  686.0  245.0  220.50  3.5   3  0.25   5  11.67  14.58\n",
      "756  0.66  759.5  318.5  220.50  3.5   2  0.40   5  14.96  17.64\n",
      "710  0.66  759.5  318.5  220.50  3.5   4  0.40   4  15.09  18.36\n",
      "693  0.76  661.5  416.5  122.50  7.0   3  0.40   4  40.40  39.67\n",
      "..    ...    ...    ...     ...  ...  ..   ...  ..    ...    ...\n",
      "71   0.76  661.5  416.5  122.50  7.0   5  0.10   1  32.21  33.67\n",
      "106  0.86  588.0  294.0  147.00  7.0   4  0.10   2  26.33  27.36\n",
      "270  0.71  710.5  269.5  220.50  3.5   4  0.10   5  10.67  14.26\n",
      "435  0.98  514.5  294.0  110.25  7.0   5  0.25   4  28.62  30.12\n",
      "102  0.90  563.5  318.5  122.50  7.0   4  0.10   2  28.83  29.36\n",
      "\n",
      "[154 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#train-validation-test\n",
    "#I will split the data into 3 as 60% train, 20% validation and 20% test.\n",
    "\n",
    "train, validate, test = np.split(df.sample(frac=1, random_state=42),\n",
    "                                [int(.6*len(df)), int(.8*len(df))])\n",
    "print(\"train \" , train)\n",
    "print(\"validate \" , validate)\n",
    "print(\"test \" , test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea845383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now i split x columns and y columns\n",
    "x_train = train.iloc[:,:-2]\n",
    "y_train = train.iloc[:,8:]\n",
    "x_valid = validate.iloc[:,:-2]\n",
    "y_valid = validate.iloc[:,8:]\n",
    "x_test = test.iloc[:,:-2]\n",
    "y_test = test.iloc[:,8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c8d2e",
   "metadata": {},
   "source": [
    "<h2> print_score function </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb9ad7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "    return math.sqrt(((x-y)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78f98794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(m):\n",
    "    m.fit(x_train,y_train)\n",
    "    \n",
    "    print(f\"R^2 of train set: {m.score(x_train, y_train)}\")\n",
    "    print(f\"R^2 of validation set: {m.score(x_valid, y_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8626068",
   "metadata": {},
   "source": [
    "<h2> Random Forest Regressor </h2>\n",
    "<p> I will try to find the RandomForestRegressor model that gives the best r^2 score by changing the max_features and max_leaf_nodes parameters with the tree numbers given below. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85728d",
   "metadata": {},
   "source": [
    "<h3> m10 = 10 tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52f24647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9605775307517177"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_features = .5, max_leaf_nodes=10)\n",
    "m.fit(x_train, y_train)\n",
    "m.score(x_train, y_train)\n",
    "m.score(x_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "135340c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m1_1 = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m1_2 = RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m1_3 = RandomForestRegressor(n_estimators=10, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m1_4 = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m1_5 = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d29dc98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9880806518514571\n",
      "R^2 of validation set: 0.9600077697798572\n"
     ]
    }
   ],
   "source": [
    "print_score(m1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0d0e9fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.996398188164646\n",
      "R^2 of validation set: 0.9734927763944191\n",
      "*********************\n",
      "R^2 of train set: 0.9956796952779898\n",
      "R^2 of validation set: 0.9741291103935839\n",
      "*********************\n",
      "R^2 of train set: 0.9818708496616224\n",
      "R^2 of validation set: 0.9787318832100618\n",
      "*********************\n",
      "R^2 of train set: 0.9905824959870366\n",
      "R^2 of validation set: 0.9766056776390311\n",
      "*********************\n",
      "R^2 of train set: 0.9930593220515449\n",
      "R^2 of validation set: 0.97793353367846\n"
     ]
    }
   ],
   "source": [
    "print_score(m1_1)\n",
    "print(\"*********************\")\n",
    "print_score(m1_2)\n",
    "print(\"*********************\")\n",
    "print_score(m1_3)\n",
    "print(\"*********************\")\n",
    "print_score(m1_4)\n",
    "print(\"*********************\")\n",
    "print_score(m1_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce9d9d",
   "metadata": {},
   "source": [
    "Since the m1_3 model gives the best r^2 score, I will use this as the RandomForestRegressor model to compare with other n_estimators parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fd8219a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m10 = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0abacd1",
   "metadata": {},
   "source": [
    "<h3> m20 = 20 tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a375ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m2_1 = RandomForestRegressor(n_estimators=20, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m2_2 = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m2_3 = RandomForestRegressor(n_estimators=20, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m2_4 = RandomForestRegressor(n_estimators=20, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m2_5 = RandomForestRegressor(n_estimators=20, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "49be25b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9965795836582008\n",
      "R^2 of validation set: 0.977201593279623\n",
      "*********************\n",
      "R^2 of train set: 0.9959077707703345\n",
      "R^2 of validation set: 0.9739533301954467\n",
      "*********************\n",
      "R^2 of train set: 0.9829721635770632\n",
      "R^2 of validation set: 0.9794495003227996\n",
      "*********************\n",
      "R^2 of train set: 0.990392157483637\n",
      "R^2 of validation set: 0.9777429407651048\n",
      "*********************\n",
      "R^2 of train set: 0.9932938749960539\n",
      "R^2 of validation set: 0.9758166603401394\n"
     ]
    }
   ],
   "source": [
    "print_score(m2_1)\n",
    "print(\"*********************\")\n",
    "print_score(m2_2)\n",
    "print(\"*********************\")\n",
    "print_score(m2_3)\n",
    "print(\"*********************\")\n",
    "print_score(m2_4)\n",
    "print(\"*********************\")\n",
    "print_score(m2_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ab57e",
   "metadata": {},
   "source": [
    "Since the m2_3 model gives the best r^2 score, I will use this as the RandomForestRegressor model to compare with other n_estimators parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "636ac980",
   "metadata": {},
   "outputs": [],
   "source": [
    "m20 = RandomForestRegressor(n_estimators=20, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33186978",
   "metadata": {},
   "source": [
    "<h3> m30 = 30 tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "41ddf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m3_1 = RandomForestRegressor(n_estimators=30, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m3_2 = RandomForestRegressor(n_estimators=30, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m3_3 = RandomForestRegressor(n_estimators=30, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m3_4 = RandomForestRegressor(n_estimators=30, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m3_5 = RandomForestRegressor(n_estimators=30, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "042129ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9966151666520702\n",
      "R^2 of validation set: 0.9774469542947077\n",
      "*********************\n",
      "R^2 of train set: 0.9966663650164855\n",
      "R^2 of validation set: 0.9732543290498091\n",
      "*********************\n",
      "R^2 of train set: 0.9827817891602917\n",
      "R^2 of validation set: 0.9794545534801269\n",
      "*********************\n",
      "R^2 of train set: 0.9905057111603782\n",
      "R^2 of validation set: 0.9789023445378096\n",
      "*********************\n",
      "R^2 of train set: 0.9939571755429409\n",
      "R^2 of validation set: 0.9778706237916464\n"
     ]
    }
   ],
   "source": [
    "print_score(m3_1)\n",
    "print(\"*********************\")\n",
    "print_score(m3_2)\n",
    "print(\"*********************\")\n",
    "print_score(m3_3)\n",
    "print(\"*********************\")\n",
    "print_score(m3_4)\n",
    "print(\"*********************\")\n",
    "print_score(m3_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea7ced",
   "metadata": {},
   "source": [
    "Since the m3_3 model gives the best r^2 score, I will use this as the RandomForestRegressor model to compare with other n_estimators parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6c74f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "m30 = RandomForestRegressor(n_estimators=30, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f55d8e",
   "metadata": {},
   "source": [
    "<h3> m40 = 40 tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4ce1330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m4_1 = RandomForestRegressor(n_estimators=40, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m4_2 = RandomForestRegressor(n_estimators=40, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m4_3 = RandomForestRegressor(n_estimators=40, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m4_4 = RandomForestRegressor(n_estimators=40, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m4_5 = RandomForestRegressor(n_estimators=40, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "46061fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9970101612169089\n",
      "R^2 of validation set: 0.9779036791002965\n",
      "*********************\n",
      "R^2 of train set: 0.9967047363570607\n",
      "R^2 of validation set: 0.9719624614480764\n",
      "*********************\n",
      "R^2 of train set: 0.9831239082823453\n",
      "R^2 of validation set: 0.9794045298082368\n",
      "*********************\n",
      "R^2 of train set: 0.9911408883781501\n",
      "R^2 of validation set: 0.9782221447823787\n",
      "*********************\n",
      "R^2 of train set: 0.9938664194397182\n",
      "R^2 of validation set: 0.9780947045352669\n"
     ]
    }
   ],
   "source": [
    "print_score(m4_1)\n",
    "print(\"*********************\")\n",
    "print_score(m4_2)\n",
    "print(\"*********************\")\n",
    "print_score(m4_3)\n",
    "print(\"*********************\")\n",
    "print_score(m4_4)\n",
    "print(\"*********************\")\n",
    "print_score(m4_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e4ea5",
   "metadata": {},
   "source": [
    "Since the m4_3 model gives the best r^2 score, I will use this as the RandomForestRegressor model to compare with other n_estimators parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "981bd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "m40 = RandomForestRegressor(n_estimators=40, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d84acf",
   "metadata": {},
   "source": [
    "<h3> m50 = 50 tree </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4eec7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m5_1 = RandomForestRegressor(n_estimators=50, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m5_2 = RandomForestRegressor(n_estimators=50, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m5_3 = RandomForestRegressor(n_estimators=50, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m5_4 = RandomForestRegressor(n_estimators=50, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m5_5 = RandomForestRegressor(n_estimators=50, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2e0d7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.996968217149897\n",
      "R^2 of validation set: 0.9773810464088855\n",
      "*********************\n",
      "R^2 of train set: 0.9968864307077103\n",
      "R^2 of validation set: 0.9737485567811439\n",
      "*********************\n",
      "R^2 of train set: 0.9830502035408093\n",
      "R^2 of validation set: 0.9790537537605919\n",
      "*********************\n",
      "R^2 of train set: 0.9908092731640654\n",
      "R^2 of validation set: 0.9772870611388831\n",
      "*********************\n",
      "R^2 of train set: 0.994263654475785\n",
      "R^2 of validation set: 0.9784521127184547\n"
     ]
    }
   ],
   "source": [
    "print_score(m5_1)\n",
    "print(\"*********************\")\n",
    "print_score(m5_2)\n",
    "print(\"*********************\")\n",
    "print_score(m5_3)\n",
    "print(\"*********************\")\n",
    "print_score(m5_4)\n",
    "print(\"*********************\")\n",
    "print_score(m5_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d0107",
   "metadata": {},
   "source": [
    "Since the m5_3 model gives the best r^2 score, I will use this as the RandomForestRegressor model to compare with other n_estimators parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "744479d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m50 = RandomForestRegressor(n_estimators=50, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989551c9",
   "metadata": {},
   "source": [
    "Now I want to see how much the score changes as I increase the number of trees more.\n",
    "I want to see the difference by doing 100 and 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "180fa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m6_1 = RandomForestRegressor(n_estimators=150, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m6_2 = RandomForestRegressor(n_estimators=150, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m6_3 = RandomForestRegressor(n_estimators=150, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m6_4 = RandomForestRegressor(n_estimators=150, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m6_5 = RandomForestRegressor(n_estimators=150, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9c219752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9972570184041105\n",
      "R^2 of validation set: 0.9781843825146721\n",
      "*********************\n",
      "R^2 of train set: 0.9968548125649741\n",
      "R^2 of validation set: 0.9736957508432196\n",
      "*********************\n",
      "R^2 of train set: 0.9831335710086467\n",
      "R^2 of validation set: 0.9791776635751221\n",
      "*********************\n",
      "R^2 of train set: 0.9908222725249729\n",
      "R^2 of validation set: 0.9780670719063431\n",
      "*********************\n",
      "R^2 of train set: 0.9944581344006764\n",
      "R^2 of validation set: 0.9789555512335587\n"
     ]
    }
   ],
   "source": [
    "print_score(m6_1)\n",
    "print(\"*********************\")\n",
    "print_score(m6_2)\n",
    "print(\"*********************\")\n",
    "print_score(m6_3)\n",
    "print(\"*********************\")\n",
    "print_score(m6_4)\n",
    "print(\"*********************\")\n",
    "print_score(m6_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "166d88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max leaf and features=0.5\n",
    "m7_1 = RandomForestRegressor(n_estimators=100, n_jobs=-1, max_features = .5)\n",
    "#max leaf and max features\n",
    "m7_2 = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "#25 leaf and max faeatures\n",
    "m7_3 = RandomForestRegressor(n_estimators=100, n_jobs=-1,max_leaf_nodes=25)\n",
    "#50 leaf and features=0.75\n",
    "m7_4 = RandomForestRegressor(n_estimators=100, n_jobs=-1, max_leaf_nodes=50\n",
    "                            , max_features = .75)\n",
    "#50 leaf and features=0.25\n",
    "m7_5 = RandomForestRegressor(n_estimators=100, n_jobs=-1, max_leaf_nodes=100\n",
    "                            , max_features = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1cb76bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9972594729648755\n",
      "R^2 of validation set: 0.9777179336590003\n",
      "*********************\n",
      "R^2 of train set: 0.9970276576129611\n",
      "R^2 of validation set: 0.9739625175487712\n",
      "*********************\n",
      "R^2 of train set: 0.9830146770698956\n",
      "R^2 of validation set: 0.9794421370362979\n",
      "*********************\n",
      "R^2 of train set: 0.9907849117883933\n",
      "R^2 of validation set: 0.9776211952697216\n",
      "*********************\n",
      "R^2 of train set: 0.9945044751484262\n",
      "R^2 of validation set: 0.978751544376911\n"
     ]
    }
   ],
   "source": [
    "print_score(m6_1)\n",
    "print(\"*********************\")\n",
    "print_score(m6_2)\n",
    "print(\"*********************\")\n",
    "print_score(m6_3)\n",
    "print(\"*********************\")\n",
    "print_score(m6_4)\n",
    "print(\"*********************\")\n",
    "print_score(m6_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd61d00",
   "metadata": {},
   "source": [
    "When I hit 100, I scored higher than both 150 and 50. Now I will try to find the number of trees trying to give the best score in between. I will only use this combination as it always scores better than the 3rd combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0c847bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "md1 = RandomForestRegressor(n_estimators=100, n_jobs=-1,max_leaf_nodes=25)\n",
    "md2 = RandomForestRegressor(n_estimators=90, n_jobs=-1,max_leaf_nodes=25)\n",
    "md3 = RandomForestRegressor(n_estimators=80, n_jobs=-1,max_leaf_nodes=25)\n",
    "md4 = RandomForestRegressor(n_estimators=70, n_jobs=-1,max_leaf_nodes=25)\n",
    "md5 = RandomForestRegressor(n_estimators=60, n_jobs=-1,max_leaf_nodes=25)\n",
    "md6 = RandomForestRegressor(n_estimators=50, n_jobs=-1,max_leaf_nodes=25)\n",
    "md7 = RandomForestRegressor(n_estimators=110, n_jobs=-1,max_leaf_nodes=25)\n",
    "md8 = RandomForestRegressor(n_estimators=120, n_jobs=-1,max_leaf_nodes=25)\n",
    "md9 = RandomForestRegressor(n_estimators=130, n_jobs=-1,max_leaf_nodes=25)\n",
    "md10 = RandomForestRegressor(n_estimators=140, n_jobs=-1,max_leaf_nodes=25)\n",
    "md11 = RandomForestRegressor(n_estimators=150, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ee2ee667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9827912587939376\n",
      "R^2 of validation set: 0.9794077442809037\n",
      "*********************\n",
      "R^2 of train set: 0.9831573214731825\n",
      "R^2 of validation set: 0.9794146984510304\n",
      "*********************\n",
      "R^2 of train set: 0.9829945580993059\n",
      "R^2 of validation set: 0.979248110099213\n",
      "*********************\n",
      "R^2 of train set: 0.9828485837962101\n",
      "R^2 of validation set: 0.9794819080811036\n",
      "*********************\n",
      "R^2 of train set: 0.9827466263646187\n",
      "R^2 of validation set: 0.9790178137440475\n",
      "*********************\n",
      "R^2 of train set: 0.9831320408327603\n",
      "R^2 of validation set: 0.9789915769946071\n",
      "*********************\n",
      "R^2 of train set: 0.9829965170575033\n",
      "R^2 of validation set: 0.9794199902789479\n",
      "*********************\n",
      "R^2 of train set: 0.9831393682105383\n",
      "R^2 of validation set: 0.9794300797355942\n",
      "*********************\n",
      "R^2 of train set: 0.9829989088848086\n",
      "R^2 of validation set: 0.9793052925211027\n",
      "*********************\n",
      "R^2 of train set: 0.9830923317073713\n",
      "R^2 of validation set: 0.9792570648366592\n"
     ]
    }
   ],
   "source": [
    "print_score(md1)\n",
    "print(\"*********************\")\n",
    "print_score(md2)\n",
    "print(\"*********************\")\n",
    "print_score(md3)\n",
    "print(\"*********************\")\n",
    "print_score(md4)\n",
    "print(\"*********************\")\n",
    "print_score(md5)\n",
    "print(\"*********************\")\n",
    "print_score(md6)\n",
    "print(\"*********************\")\n",
    "print_score(md7)\n",
    "print(\"*********************\")\n",
    "print_score(md8)\n",
    "print(\"*********************\")\n",
    "print_score(md9)\n",
    "print(\"*********************\")\n",
    "print_score(md10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f59e6c",
   "metadata": {},
   "source": [
    "Model 4 performed better than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "76f99c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m70 = RandomForestRegressor(n_estimators=70, n_jobs=-1,max_leaf_nodes=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa518ff",
   "metadata": {},
   "source": [
    "<h3> Best RandomForestRegressor Model Selection </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bdc5f954",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9824256656174482\n",
      "R^2 of validation set: 0.9778517570620489\n",
      "*********************\n",
      "R^2 of train set: 0.9826153193834573\n",
      "R^2 of validation set: 0.9787115066820639\n",
      "*********************\n",
      "R^2 of train set: 0.9829090320149236\n",
      "R^2 of validation set: 0.979144110933814\n",
      "*********************\n",
      "R^2 of train set: 0.9829008335073481\n",
      "R^2 of validation set: 0.9787572945377525\n",
      "*********************\n",
      "R^2 of train set: 0.9828700781492679\n",
      "R^2 of validation set: 0.979132994555967\n",
      "*********************\n",
      "R^2 of train set: 0.9830878804311725\n",
      "R^2 of validation set: 0.9793358161689694\n"
     ]
    }
   ],
   "source": [
    "print_score(m10)\n",
    "print(\"*********************\")\n",
    "print_score(m20)\n",
    "print(\"*********************\")\n",
    "print_score(m30)\n",
    "print(\"*********************\")\n",
    "print_score(m40)\n",
    "print(\"*********************\")\n",
    "print_score(m50)\n",
    "print(\"*********************\")\n",
    "print_score(m70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732abb7a",
   "metadata": {},
   "source": [
    "The m50 and m70 models give very close scores to each other. Sometimes one gives a better score, sometimes the other.\n",
    "That's why I want to compare both of them with the test data in the final stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c9b63600",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model1 = m50\n",
    "rfr_model2 = m70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813f89b",
   "metadata": {},
   "source": [
    "<h2> Linear Regression </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e640d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of train set: 0.9024829375666665\n",
      "R^2 of validation set: 0.9032843577136344\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)\n",
    "print_score(lr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645fed1",
   "metadata": {},
   "source": [
    "<h2> Compare these 3 models </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "35d290ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor with 50 n_estimators\n",
      "\n",
      "R^2 of train set: 0.9830105146442695\n",
      "R^2 of validation set: 0.9788176469804055\n",
      "\n",
      "*********************\n",
      "\n",
      "RandomForestRegressor with 70 n_estimators\n",
      "\n",
      "R^2 of train set: 0.9828391996567383\n",
      "R^2 of validation set: 0.9791808105921496\n",
      "\n",
      "*********************\n",
      "\n",
      "Linear Regression\n",
      "\n",
      "R^2 of train set: 0.9024829375666665\n",
      "R^2 of validation set: 0.9032843577136344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestRegressor with 50 n_estimators\")\n",
    "print()\n",
    "print_score(rfr_model1)\n",
    "print()\n",
    "print(\"*********************\")\n",
    "print()\n",
    "print(\"RandomForestRegressor with 70 n_estimators\")\n",
    "print()\n",
    "print_score(rfr_model2)\n",
    "print()\n",
    "print(\"*********************\")\n",
    "print()\n",
    "print(\"Linear Regression\")\n",
    "print()\n",
    "print_score(lr_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397aaa2",
   "metadata": {},
   "source": [
    "Now let's look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ae660b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score2(m):\n",
    "    m.fit(x_train,y_train)\n",
    "    \n",
    "    print(f\"R^2 of train set: {m.score(x_train, y_train)}\")\n",
    "    print(f\"R^2 of validation set: {m.score(x_valid, y_valid)}\")\n",
    "    print(f\"R^2 of test set: {m.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6c481ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor with 50 n_estimators\n",
      "\n",
      "R^2 of train set: 0.9825221850974113\n",
      "R^2 of validation set: 0.9786415052921925\n",
      "R^2 of test set: 0.9795738581796989\n",
      "\n",
      "*********************\n",
      "\n",
      "RandomForestRegressor with 70 n_estimators\n",
      "\n",
      "R^2 of train set: 0.9828634388750188\n",
      "R^2 of validation set: 0.9793689059714474\n",
      "R^2 of test set: 0.9801043053275207\n",
      "\n",
      "*********************\n",
      "\n",
      "Linear Regression\n",
      "\n",
      "R^2 of train set: 0.9024829375666665\n",
      "R^2 of validation set: 0.9032843577136344\n",
      "R^2 of test set: 0.8907347170836288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestRegressor with 50 n_estimators\")\n",
    "print()\n",
    "print_score2(rfr_model1)\n",
    "print()\n",
    "print(\"*********************\")\n",
    "print()\n",
    "print(\"RandomForestRegressor with 70 n_estimators\")\n",
    "print()\n",
    "print_score2(rfr_model2)\n",
    "print()\n",
    "print(\"*********************\")\n",
    "print()\n",
    "print(\"Linear Regression\")\n",
    "print()\n",
    "print_score2(lr_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1396c",
   "metadata": {},
   "source": [
    "Again, the RFR model, which we have given as n_estimators 50 and 70, gives values close to each other. Linear Regression performed approximately 10% worse than RFR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc25eb",
   "metadata": {},
   "source": [
    "As a result, we have a model that predicts the result with 98% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
